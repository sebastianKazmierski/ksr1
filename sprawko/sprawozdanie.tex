\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\graphicspath{ {./images/} }

\studycycle{Informatyka, studia dzienne, I st.}
\coursesemester{VI}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2019/2020}

\courseteacher{Marcin Kacprowicz}
\coursegroup{wtorek, 14:00}

\author{
  \studentinfo{Sebastian Kaźmierski}{216795} \and
  \studentinfo{Bartosz Paluszkiewicz}{216856} 
}

\title{Zadanie 1: Ekstrakcja cech, miary podobieństwa, klasyfikacja}


\begin{document}
\maketitle

\section{Cel}
{
Celem zadania jest stworzenie aplikacji która wykorzystując metodę Knn będzie wykonywała klasyfikację artykułów w dwóch kategoriach (Places,Topics). Aplikacja ma również implementować moduł ekstrakcji cech który będzie obliczał wartości cech klasyfikowanych artykułów. Po stworzeniu aplikacji przy jej wykorzystaniu zostaną przeprowadzone eksperymenty z różnymi wartościami parametrów metody Knn.}

\section{Wprowadzenie}
\subsection{Klasyfikator}
Zaimplementowany klasyfikator zbioru tekstów wykorzystuje algorytm k najbliższych sąsiadów (k-nn, k nearest keighbours), który jest jednym z bezparametrowych metod klasyfikacji statystycznej.\newline
W trakcie działania nie tworzy wewnętrznej reprezentacji danych uczących, lecz przechowuje wszystkie wzore uczące i dopiero w momencie pojawienia się wzorca testującego szuka rozwiązania, wyznaczając odległość do wszystkich wzorców.\newline
Bezparametrowość algorytmu objawia się brakiem założeń co do rozkładu podstawowych danych, np. rozkładu jednostajnego.\newline\newline

\subsection{Wektor cech}
Do ekstrakcji danych wykorzystaliśmy wektor następujących cech:
\begin{enumerate}
  \item Liczba wszystkich słów kluczowych w pierwszych 10\% procentach tekstu
  \item Liczba wszystkich słów kluczowych w całym tekście
  \item Liczba wszystkich nazw własnych w stosunku do liczby słów w tekście (po stop liście)
  \item Średnia długość unikalnych nazw własnych 
  \item Długość tekstu (liczba wszystkich słów po stop liście)
  \item Liczba słów które występują więcej niż raz w stosunku do długości tekstu (po stop liście i po stemizacji)
  \item Średnia długość zdań (liczba słów) (po stop liście i  po stemizacji)
  \item Liczba unikalnych słów w stosunku do długości tekstu (po stop liście)
  \item Liczba akapitów w stosunku do długości tekstu (po stop liście)
  \item Średnia długość akapitu (liczba słów) (przed stop listą)
  \item Liczba wszystkich słów usuniętych przez stop listę w stosunku do długości tekstu po stop liście
  \item Liczba słów kluczowych dla WEST\_GERMANY
  \item Liczba słów kluczowych dla USA
  \item Liczba słów kluczowych dla FRANCE
  \item Liczba słów kluczowych dla UK
  \item Liczba słów kluczowych dla CANADA
  \item Liczba słów kluczowych dla JAPAN
  \newline
  \newline
  * nazwa własna – słowo pisane wielką literą które nie jest na początku zdania lub jest na początku zdania, ale przynajmniej raz występuje w środku\newline
* długość tekstu – liczba wszystkich słów w tekście
\end{enumerate}

\subsection{Zastosowane metryki}
Do obliczania odległości zastosowaliśmy trzy metryki (2.3.1 - 2.3.3), miarę własną (2.3.6) oraz dwie miary prawdopodobieństwa (2.3.4, 2.3.5). Ze względu na to, że miary podobieństwa służą określaniu "bliskości" wektorów, a nie odległości między nimi, do obliczeń musieliśmy wykorzystać odwrotności uzyskanych wartości. 
\subsubsection{Metryka Euklidesa}
Odległość euklidesową określamy pierwiastek sumy kwadratów różnic wartości cech wektorów A, B i opisujemy wzorem:

\begin{equation}
d(A, B) =  \sqrt{\sum_{i=1}^n((x_{iA} - x_{iB})^2)}
\end{equation}

\subsubsection{Metryka Czebyszewa}
Odległością Czebyszewa określamy największy moduł różnic między wartościami cechami wektorów A, B i określamy wzorem:

\begin{equation}
d(A, B) =  \mathop{max}_{i}|x_{iA} - x_{iB}|
\end{equation}

\subsubsection{Metryka Uliczna}
Odległością w metryce ulicznej (odległością taksówkową, uliczną, Manhattan) nazywamy sumę modułów różnic wartości w każdym wymiarze wektorów A, B i określamy wzorem:
\begin{equation}
d(A, B) =  \sum_{i=1}^n|x_{iA} - x_{iB}|
\end{equation}
\subsubsection{Minimum - maksimum}
Odległość między wketorami A, B określamy jako odwrotność stosunku sumy minimów wartości cech do sumy maksimów wartości cech, czyli stosunek maksimów do minimów wartości cech wektorów.
\begin{equation}
d(A, B) = (\frac{\sum_{i=1}^n{min(x_{iA}, x_{iB})}}{\sum_{i=1}^n{max(x_{iA}, x_{iB})}})^-1 = \frac{\sum_{i=1}^n{max(x_{iA}, x_{iB})}}{\sum_{i=1}^n{min(x_{iA}, x_{iB})}}
\end{equation}

\subsubsection{Średnia arytmetyczna - minimum}
Odległość między wektorami A, B określamy jako odwrotność stosunku sumy minimalnych wartości cech wektorów i średniej arytmetycznej wartości cech wektorów, czyli stosunek średniej arytmetycznej do sumy minimów wartości cech wektorów.

\begin{equation}
d(A, B) =  (\frac{\sum_{i=1}^n{min(x_{iA}, x_{iB})}}{\frac{1}{2}\sum_{i=1}^n({x_{iA} + x_{iB}})})^-1 = \frac{\frac{1}{2}\sum_{i=1}^n({x_{iA} + x_{iB}})}{\sum_{i=1}^n{min(x_{iA}, x_{iB})}}
\end{equation}
\subsubsection{Miara własna}
Odległość obliczoną przy użyciu autorskiej miary określamy jako sumę iloczynów ułożonych rosnąco różnic wartości między cechami wektora i współczynnika zależnego od pozycji tej odległości w posortowanym zbiorze, a także wielkości zbioru.
\begin{equation}
d(A, B) =  \sum_{i=0}^{N-1}C_i(1 - \frac{i}{2N})
\end{equation}
\begin{equation}
C(A,B) =  (\sum_{i=1}^N|x_{A} - x_{iB}|)\uparrow
\end{equation}

\subsection{Miary jakości}
\subsubsection{Accuracy - dokładność}
Dokładnością nazywamy stosunek liczby poprawnych prognoz do wszystkich wykonanych prognoz,

\begin{equation}
accuracy = \frac{correct\ predictions}{total\ predictions}
\end{equation}

W celu obliczenia kolejnych miar tworzymy macierz błędu, której uproszczoną formą jest poniższa tabela [2]:

\begin{center}
	\begin{tabular}{ |c|c|c|c| } 
	\hline
	 & Positive prediction & Negative prediction \\
	\hline
	Positive class & True Positive (TP) & False Negative (FN) \\ 
	\hline
	Negative class & False Positive (FP) & True Negative (TN) \\ 
	\hline
	\end{tabular}
\end{center}

W naszym przypadku musimy zakwalifikować 6, a nie 2 klasy, więc macierz błędu ma w rzeczywistości wymiary 6 x 6.

\subsubsection{Precision - precyzja}
Precyzja określa stosunek poprawnie zakwalifikowanych obiektów danej klasy do wszystkich prognoz, które wskazują na tę klasę (suma słusznie i niesłusznie zakwalifikowanych obiektów)

\begin{equation}
precision = \frac{\sum_{c}^C{True Positive_c}}{\sum_{c}^C({True Positive_c + False Positive_c})}
\end{equation}

\subsubsection{Recall - skuteczność}
Skuteczność określa stosunek poprawnie zakwalifikowanych obiektów danej klasy do sumy poprawnie zakwalifikowanych i poprawnie odrzuconych obiektów 

\begin{equation}
recall = \frac{\sum_{c}^C{True Positive_c}}{\sum_{c}^C({True Positive_c + False Negative_c})}
\end{equation}


\section{Opis implementacji}
{
Podstawową klasą jest klasa „Article” która przechowuje w sobie treść artykułu oraz informację o etykiecie którą ten artykuł jest oznaczony. Wszystkie artykuły są przechowywane w obiekcie klasy „ArticleStore” która odpowiada za podział artykułów na zbiór uczący i testowy. Podczas tworzenia programu został wykorzystany wzorzec projektowy strategii a świadczą o tym interfejsy „FeatureExtractors” implementowany przez klasy które są odpowiedzialne za obliczanie wartości cech tekstu oraz „DistanceMeasurement” implementowany przez klasy które reprezentują poszczególne miary/metryki. Klasa „NeigboursSpaceCreator” jest odpowiedzialna za przygotowanie zbioru uczącego czyli przechowywanie wartości cech dla artykułów ze zbioru uczącego. Klasa „Knn” na podstawie k najbliższych sąsiadów przydziela elementowi ze zbioru uczącego odpowiednią etykietę.
Program został napisany w języku Java w wersji 13.

\begin{figure}[H]
\caption{Diagram UML}
\centering
\includegraphics[width=1\textwidth]{uml}
\end{figure}
 }

\section{Materiały i metody}

{
Badania zostały przeprowadzone na zbiorze artykułów w języku angielskim które były oznaczone etykietami w dwóch kategoriach w kategorii „places” (west-germany, usa, france,uk ,canada, japan) oraz w kategorii „topics” (earn, acq) 

\subsection{Wpływ liczby sąsiadów na jakość klasyfikacji}
Badanie zostało przeprowadzone z różna ilością sąsiadów {1,3,4,7,11,12,13,19,37,59}
Pozostałe parametry były stałe:
\\*
Metryka: Metryka Euklidesa
\\*
Podział danych: 70\% - zbiór uczący (Places), 50\% - zbiór uczący (Topics)
\\*
Cechy: 1,2,3,4,5,6,7,8,9,10,11
\subsection{Wpływ podziału danych na jakość klasyfikacji}
Badanie zostało przeprowadzone z różną wielkość zbioru uczącego {30\%,40\%,50\%,60\%,70\%}
Pozostałe parametry były stałe:
\\*
Metryka: Metryka Euklidesa
\\*
Liczba sąsiadów: 37
\\*
Cechy: 1,2,3,4,5,6,7,8,9,10,11
\subsection{Wpływ metryki/miary na jakość klasyfikacji}
Badanie zostało przeprowadzone z różnymi metrykami/miarami: {Średnia arytmetyczna minimum, Metryka Czebyszewa, Metryka Euklidesa, Minimum-maximum, Metryka Uliczna, Nasza Metryka}
Pozostałe parametry były stałe:
\\*
Podział danych: 60\% - zbiór uczący (Places), 50\% - zbiór uczący (Topics)
\\*
Liczba sąsiadów: 37
\\*
Cechy: 1,2,3,4,5,6,7,8,9,10,11
\subsection{Wpływ cech na jakość klasyfikacji}
Badania zostały przeprowadzone w taki sposób, że od podstawowego zbioru cech czyli cech: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 odejmowaliśmy jedną cechę (lub dodawaliśmy w przypadku cech związanych z etykietami) i najbardziej interesujące przypadki zamieściliśmy w wynikach. 
Pozostałe parametry były stałe:
\\*
Metryka: Metryka Euklidesa (Topics), Metryka Uliczna (Places)
\\*
Liczba sąsiadów: 37
\\*
Podział danych: 60\%
\subsection{Prównanie naszej metryki i metryki Czebyszewa}
Badanie zostało przeprowadzone z różna ilością sąsiadów {1,3,4,7,11,12,13,19,37,59} i przy użyci Naszej Metryki i Metryki Czebyszewa
Pozostałe parametry były stałe:
\\*
Podział danych: 60\%
\\*
Cechy: 1,2,3,4,5,6,7,8,9,10,11
}

\section{Wyniki}
{
\subsection{Wyniki klasyfikacji metodą k-NN dla 10 różnych wartości parametru k (Places)}

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla różnej liczby sąsiadów}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Liczba sąsiadów} & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
1                        & 0,697             & 0,314                  & 0,287             \\ \hline
3                        & 0,736             & 0,307                  & 0,292             \\ \hline
4                        & 0,754             & 0,311                  & 0,305             \\ \hline
7                        & 0,789             & 0,309                  & 0,363             \\ \hline
11                       & 0,807             & 0,301                  & 0,398             \\ \hline
12                       & 0,806             & 0,290                  & 0,372             \\ \hline
13                       & 0,81              & 0,291                  & 0,373             \\ \hline
19                       & 0,812             & 0,263                  & 0,364             \\ \hline
37                       & 0,814             & 0,246                  & 0,538             \\ \hline
59                       & 0,811             & 0,229                  & 0,369             \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[H]
\caption{Accuracy w zależności od liczby sąsiadów}
\centering
\includegraphics[width=1\textwidth]{i1}
\end{figure}

\begin{figure}[H]
\caption{Recall i Precision w zależności od liczby sąsiadów}
\centering
\includegraphics[width=1\textwidth]{i2}
\end{figure}

\subsection{Wyniki klasyfikacji metodą k-NN dla 5 różnych podziałów na zbiór uczący i testowy (Places)}

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla różnych podziałów na zbiór uczący i testowy}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Ilość danych\\ w zbiorze uczący\end{tabular}} & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
30\%                                                                             & 0,811             & 0,229                  & 0,387                     \\ \hline
40\%                                                                             & 0,808             & 0,235                  & 0,369                     \\ \hline
50\%                                                                             & 0,809             & 0,240                  & 0,334                     \\ \hline
60\%                                                                             & 0,817             & 0,239                  & 0,404                     \\ \hline
70\%                                                                             & 0,814             & 0,246                  & 0,538                     \\ \hline
\end{tabular}
\end{center}
\end{table}


\begin{figure}[H]
\caption{Accuracy w zależności od podziału na zbiór uczący i testowy}
\centering
\includegraphics[width=1\textwidth]{i3}
\end{figure}

\begin{figure}[H]
\caption{Recall i Precision w zależności od podziału na zbiór uczący i testowy}
\centering
\includegraphics[width=1\textwidth]{i4}
\end{figure}

\subsection{Wyniki klasyfikacji metodą k-NN dla 6 różnych metryk/miar (Places)}

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla różnych metryk/miar}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Metryka}             & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
Średnia arytmetyczna minimum & 0,819             & 0,229                  & 0,384                     \\ \hline
Metryka Czebyszewa           & 0,815             & 0,223                  & 0,379                     \\ \hline
Metryka Euklidesa            & 0,817             & 0,238                  & 0,399                     \\ \hline
Minimum-maximum              & 0,819             & 0,229                  & 0,384                     \\ \hline
Metryka Uliczna              & 0,821             & 0,242                  & 0,407                     \\ \hline
Nasza metryka                & 0,821             & 0,242                  & 0,42                      \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[H]
\caption{Accuracy w zależności od miary/metryki}
\centering
\includegraphics[width=1\textwidth]{i5}
\end{figure}

\begin{figure}[H]
\caption{Recall i Precision w zależności od miary/metryki}
\centering
\includegraphics[width=1\textwidth]{i6}
\end{figure}


\subsection{Wyniki klasyfikacji metodą k-NN dla różnych cech (Places)}
Podstawowe cechy to 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11
\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla 4 podzbiorów cech}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Różnice pomiędzy \\ cechami podstawowymi\end{tabular}} & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
Cechy podstawowe                                                                          & 0,817             & 0,238                  & 0,399                     \\ \hline
\begin{tabular}[c]{@{}c@{}}Dodatkowe cechy:\\ 12 13 14 15 16 17\end{tabular}              & 0,875             & 0,492                  & 0,892                     \\ \hline
Brak cechy 8                                                                              & 0,805             & 0,179                  & 0,25                      \\ \hline
Brak cechy 6                                                                              & 0,811             & 0,22                   & 0,351                     \\ \hline
Brak cechy 9                                                                              & 0,819             & 0,241                  & 0,417                     \\ \hline
\end{tabular}
\end{center}
\end{table}

\subsection{Wyniki klasyfikacji metodą k-NN dla 10 różnych wartości parametru k}

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla różnej liczby sąsiadów (Topics)}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Liczba sąsiadów} & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
1                        & 0,87              & 0,86                   & 0,859                     \\ \hline
3                        & 0,892             & 0,889                  & 0,881                     \\ \hline
4                        & 0,896             & 0,905                  & 0,883                     \\ \hline
7                        & 0,907             & 0,907                  & 0,896                     \\ \hline
11                       & 0,914             & 0,917                  & 0,902                     \\ \hline
12                       & 0,914             & 0,921                  & 0,902                     \\ \hline
13                       & 0,912             & 0,916                  & 0,901                     \\ \hline
19                       & 0,913             & 0,918                  & 0,902                     \\ \hline
37                       & 0,917             & 0,925                  & 0,905                     \\ \hline
59                       & 0,911             & 0,922                  & 0,899                     \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[H]
\caption{Accuracy w zależności od liczby sąsiadów}
\centering
\includegraphics[width=1\textwidth]{i7}
\end{figure}

\begin{figure}[H]
\caption{Recall i Precision w zależności od liczby sąsiadów}
\centering
\includegraphics[width=1\textwidth]{i8}
\end{figure}

\subsection{Wyniki klasyfikacji metodą k-NN dla 5 różnych podziałów na zbiór uczący i testowy (Topics)}

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla różnych podziałów na zbiór uczący i testowy}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Podział danych} & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
30,00\%                 & 0,912             & 0,921                  & 0,901                     \\ \hline
40,00\%                 & 0,906             & 0,921                  & 0,893                     \\ \hline
50,00\%                 & 0,917             & 0,925                  & 0,905                     \\ \hline
60,00\%                 & 0,921             & 0,926                  & 0,909                     \\ \hline
70,00\%                 & 0,915             & 0,925                  & 0,902                     \\ \hline
\end{tabular}
\end{center}
\end{table}


\begin{figure}[H]
\caption{Accuracy w zależności od podziału na zbiór uczący i testowy}
\centering
\includegraphics[width=1\textwidth]{i11}
\end{figure}

\begin{figure}[H]
\caption{Recall i Precision w zależności od podziału na zbiór uczący i testowy}
\centering
\includegraphics[width=1\textwidth]{i12}
\end{figure}

\subsection{Wyniki klasyfikacji metodą k-NN dla 6 różnych metryk/miar (Topics)}

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla różnych metryk/miar}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Metryka}             & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
Średnia arytmetyczna minimum & 0,905             & 0,918                  & 0,893                     \\ \hline
Metryka Czebyszewa           & 0,911             & 0,919                  & 0,899                     \\ \hline
Metryka Euklidesa            & 0,917             & 0,925                  & 0,905                     \\ \hline
Minimum-maximum              & 0,905             & 0,918                  & 0,893                     \\ \hline
Metryka Uliczna              & 0,911             & 0,92                   & 0,899                     \\ \hline
Nasza metryka                & 0,907             & 0,916                  & 0,894                     \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{figure}[H]
\caption{Accuracy w zależności od miary/metryki}
\centering
\includegraphics[width=1\textwidth]{i9}
\end{figure}

\begin{figure}[H]
\caption{Recall i Precision w zależności od miary/metryki}
\centering
\includegraphics[width=1\textwidth]{i10}
\end{figure}

\subsection{Wyniki klasyfikacji metodą k-NN dla różnych cech (Topics)}

Podstawowe cechy to 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11

\begin{table}[h]
\begin{center}
\caption{Wyniki klasyfikacji dla 4 podzbiorów cech}
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{\begin{tabular}[c]{@{}c@{}}Różnice pomiędzy \\ cechami podstawowymi\end{tabular}} & \textbf{Accuracy} & \textbf{Średni Recall} & \textbf{Średni Precision} \\ \hline
Cechy podstawowe                                                                          & 0,921             & 0,926                  & 0,909                     \\ \hline
Dodatkowe cechy: 12 13                                                                    & 0,938             & 0,944                  & 0,926                     \\ \hline
Brak cechy 11                                                                             & 0,894             & 0,899                  & 0,88                      \\ \hline
Brak cechy 3                                                                              & 0,871             & 0,888                  & 0,861                     \\ \hline
Brak cechy 10                                                                             & 0,925             & 0,928                  & 0,913                     \\ \hline
\end{tabular}
\end{center}
\end{table}

\subsection{Porównanie naszej metryki z metryką Czebyszewa  (Places)}

\begin{table}[H]
\begin{center}
\caption{Wyniki klasyfikacji dla 4 podzbiorów cech}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Liczba sąsiadów} & \textbf{\begin{tabular}[c]{@{}c@{}}Accuracy \\ Nasza Metryka\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Accuracy\\ Metryka Czebyszewa\end{tabular}} \\ \hline
1                        & 0,701                                                                      & 0,694                                                                          \\ \hline
3                        & 0,751                                                                      & 0,735                                                                          \\ \hline
4                        & 0,763                                                                      & 0,749                                                                          \\ \hline
7                        & 0,802                                                                      & 0,79                                                                           \\ \hline
11                       & 0,816                                                                      & 0,803                                                                          \\ \hline
12                       & 0,816                                                                      & 0,804                                                                          \\ \hline
13                       & 0,816                                                                      & 0,806                                                                          \\ \hline
19                       & 0,819                                                                      & 0,813                                                                          \\ \hline
37                       & 0,821                                                                      & 0,815                                                                          \\ \hline
59                       & 0,817                                                                      & 0,814                                                                          \\ \hline
\end{tabular}
\end{center}
\end{table}
}

\section{Dyskusja}
{

Liczba sąsiadów

W poniższej dyskusji odwołujemy się do Rysunków 2 i 8 oraz Tabel 1 i 5

Po wyznaczeniu klasyfikacji metodą Knn dla różnej liczby sąsiadów otrzymaliśmy podobne wyniki w przypadku klasyfikacji w kategorii „places” (6 etykiet) i „topic” (2 etykiety). W obu przypadkach można zauważyć znaczy wzrost dokładności klasyfikacji przy zwiększaniu liczby sąsiadów od 1 do 11. Wynika z tego, że zbyt mała liczba sąsiadów znacznie obniża accuracy klasyfikacji. Powyżej 11 sąsiadów accuracy w przypadku kategorii „topic” się stabilizuje i waha wokół wartości osiągniętej w przypadku 11 sąsiadów.  W przypadku kategorii „places” accuracy bardzo powoli ale jednak rośnie aż do 37 sąsiadów. Wynika z tego, że liczba sąsiadów przy której metoda Knn osiąga największe accuracy rośnie wraz z liczbą etykiet na które dzielimy dany zbiór. Wynika z tego również, że zbyt duża liczba sąsiadów zwiększa tylko czas obliczeń a nie poprawia otrzymanego wyniku.
\\*
\par Podział danych na zbiór uczący i testowy

Poniżej odwołujemy się do Rysunków 4 i 10 oraz Tabel 2 i 6

W oby kategoriach „places” i „topic” otrzymaliśmy podobne wyniki. Różnica pomiędzy najlepszym i najgorszym wynikiem nie przekraczała 2\%. Najlepszy wynik otrzymaliśmy dla podziału 60\% danych na zbiór uczący oraz 4\% danych na zbiór testowy. Natomiast najgorszy wynik otrzymaliśmy w zestawie który jest lustrzanym odbiciem poprzedniego czyli 40\% na zbiór uczący i 60\% na zbiór testowy. Wynika z tego, że podział na zbiór uczący i testowy nie ma dużego wpływu na otrzymane wyniki. Wynika z tego również, że to który podział jest najlepszy a który najgorszy jest niezależne od kategorii i ilości etykiet według których chcemy klasyfikować nasze dane. Dodatkowo wynika z tego że podział 60\% na zbiór uczący i 40\% na zbiór testowy jest dużo lepszym podziałem niż podział 40\% na zbiór uczący i 60\% na zbiór testowy.
\\*
\par Miara/Metryka

Poniżej odwołujemy się do Rysunków 6 i 12 oraz Tabel 3 i 7

W obu kategoriach „places” i „topic” otrzymaliśmy różne wyniki. Różnica pomiędzy najlepszym a najgorszym wynikiem znowu nie przekracza 2\%. W przypadku kategorii „places” dwie najlepsze metryki to „Metryka Uliczna” i „Nasza Metryka” a dwie najgorsze to „Metryka Euklidesa” i „Metryka Czebyszewa”. W przypadku kategorii „topic” dwie najlepsze metryki to „Metryka Czebyszewa” i „Metryka Euklidesa” a dwie najgorsze to „Średnia arytmetyczna minimum” i „Minimum maximum”. Wynika z tego, że metryka nie ma dużego wpływu na wynik. Wynika z tego również, że to która metryka jest najlepsza zależny od kategorii oraz ilości etykiet na które dzielimy nasz zbiór.
\\*
\par Różne cechy.

Poniżej odwołujemy się do Tabel 4 i 8

W przypadku kategorii „places” znaczną przewagę nad innymi mają cechy z słowami kluczowymi dla poszczególnych etykiet (jednak jest ich 6 i muszą występować wszystkie razem). Wyniki dla pozostały cech bardzo mało się różnią. Jednak za dwie najlepsze to cechy 8 i 6 a za najgorszą ponieważ jej obecność pogarsza wynik cechę 9 W przypadku kategorii „topic” cech ze słowami kluczowymi dla poszczególny etykiet nie mają już tak dużego wpływu jak poprzednio. Dwie najlepsze cechy w tym przypadku to 11 i 3 a najgorsza jest cecha 10.. Wynika z tego, że jakość cechy bardzo mocno zależy od kategorii oraz etykiet na które dzielimy nasz zbiór. 
}
\section{Wnioski}
{
\begin{enumerate}
\item  Znaczny wzrost accuracy występuje wraz ze wzrostem liczby sąsiadów ale tylko to pewnego momentu.
\item  Zbyt duża liczba sąsiadów od pewnego momentu nie zwiększa już accuracy
\item  Optymalna liczba sąsiadów jest niezależna od liczby etykiet na które dzielimy dany zbiór
\item  Podział danych na zbiór uczący i testowy nie ma dużego wpływu na wyniki. 
\item  To który podział jest najlepszy a który najgorszy jest nie zależne od kategorii i ilości etykiet na które dzielimy nasz zbiór
\item  Najlepszy jest podział 60\% na zbiór uczący i 40\% na zbiór testowy a najgorszy 40\% na zbiór testowy i 60\% na zbiór uczący.
\item  Metryka nie ma dużego wpływu na accuracy otrzymanego wyniku
\item  To która metryka jest najlepsza silnie zależy od kategorii i tego na jakie etykiety dzielimy nasz zbiór.
\item  Cechy mają duży wpływ na otrzymane wyniki.
\item  To które cechy są najlepsze silnie zależy od kategorii i tego na jakie etykiety dzielimy nasz zbiór. 

\end{enumerate}
}


\begin{thebibliography}{0}
[1] Adam Niewiadomski "Materiały, przykłady i ćwiczenia do przedmiotu Komputerowe Systemy Rozpoznawania 1" \newline
[2] https://machinelearningmastery.com/\newline
precision-recall-and-f-measure-for-imbalanced-classification/\newline
[3] https://machinelearningmastery.com/confusion-matrix-machine-learning/\newline
[4] http://home.agh.edu.pl/horzyk/lectures/miw/KNN.pdf\newline
\end{thebibliography}
\end{document}
